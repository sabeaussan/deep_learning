{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNetCifar.ipynb","provenance":[],"authorship_tag":"ABX9TyOUTRqR1Ns6x4QrEEjutGNt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"kdE44Z3s8jLK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593443924660,"user_tz":-120,"elapsed":4506,"user":{"displayName":"Samuel Beaussant","photoUrl":"","userId":"05395758280539869398"}}},"source":["import numpy as np\n","import torchvision\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchsummary import summary\n","import torchvision.models as models"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bm7jjTBl8wLT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1593443948502,"user_tz":-120,"elapsed":21960,"user":{"displayName":"Samuel Beaussant","photoUrl":"","userId":"05395758280539869398"}},"outputId":"258674a3-db7d-4976-8495-7bd3a8037f61"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OoXcCVIQ-TVU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593443962563,"user_tz":-120,"elapsed":961,"user":{"displayName":"Samuel Beaussant","photoUrl":"","userId":"05395758280539869398"}}},"source":["#TODO : def create_ResNet\n","\n","\n","def create_ResNet(n_blocks,n_channels,n_filters,n_layers=2,down_sample = True):\n","  \"\"\"\n","        args :\n","            n_blocks : number of residual block to stack\n","            n_filters : number of filters for every conv\n","            n_channels : number of input channels\n","            n_layers : number of conv for each block\n","            down_sample : should down_sample data with stride of 2, most of the time\n","                down_sampling is done at the beginig of every batch\n","    \"\"\"\n","    blocks = []\n","    for i in range(n_blocks):\n","        blocks += [ResidualBlock(\n","            n_layers,\n","            n_channels if i ==0 else n_filters,\n","            n_filters,\n","            down_sample = down_sample if i ==0 else False\n","        )]\n","    return nn.Sequential(*blocks)\n","        \n","\n","class ResNet34(nn.Module):\n","    \"\"\"\n","        Build a ResNet model with 34 layers\n","        agrs :\n","            n_channels : number of channels input\n","            input_size : size of the input data\n","            output_dim : number of class to classify\n","            \n","    \"\"\"\n","    def __init__(self,n_channels,input_size,output_dim):\n","        self.n_filters = 64\n","        super(ResNet34, self).__init__()   \n","        self.n_channels = n_channels\n","        self.input_size = input_size\n","        self.base_conv = nn.Sequential(\n","            nn.Conv2d(n_channels,self.n_filters,3, stride = 1,padding = 1),\n","        #    nn.MaxPool2d(3,2,1)\n","        )\n","        self.conv3x3_1 = create_ResNet(3,self.n_filters,self.n_filters,down_sample = False)\n","        self.conv3x3_2 = create_ResNet(4,self.n_filters,self.n_filters*2)\n","        self.conv3x3_3 = create_ResNet(6,self.n_filters*2,self.n_filters*4)\n","        self.conv3x3_4 = create_ResNet(3,self.n_filters*4,self.n_filters*8)\n","        self.flat = self.compute_out_shape()\n","        self.avg_pooling = nn.AvgPool2d(self.flat[-1])\n","        self.fc = nn.Linear(self.flat[1],output_dim)\n","        \n","        \n","    def compute_out_shape(self):\n","        # Compute the shape of the output tensor of the convNet\n","        x = torch.FloatTensor(np.ones((1,self.n_channels,self.input_size,self.input_size)))\n","        x = self.base_conv(x)\n","        x = self.conv3x3_1(x)\n","        x = self.conv3x3_2(x)\n","        x = self.conv3x3_3(x)\n","        x = self.conv3x3_4(x)\n","        return x.shape\n","        \n","    def forward(self, x):\n","        x = self.base_conv(x)\n","        x = self.conv3x3_1(x)\n","        x = self.conv3x3_2(x)\n","        x = self.conv3x3_3(x)\n","        x = self.conv3x3_4(x)\n","        x = self.avg_pooling(x)\n","        x = x.view(-1,self.flat[1])\n","        x = self.fc(x)\n","        return F.softmax(x)\n","    \n","    \n","        \n","\n","class ResNet18(nn.Module):\n","    \"\"\"\n","        Build a ResNet model with 18 layers\n","        agrs :\n","            n_channels : number of channels input\n","            input_size : size of the input data\n","            output_dim : number of class to classify\n","    \"\"\"\n","    def __init__(self,n_channels,input_size,output_dim):\n","        self.n_filters = 64\n","        super(ResNet18, self).__init__()   \n","        self.n_channels = n_channels\n","        self.input_size = input_size\n","        self.base_conv = nn.Sequential(\n","            nn.Conv2d(n_channels,self.n_filters,3, stride = 2,padding = 3),\n","            nn.MaxPool2d(3,2,1)\n","        )\n","        self.conv3x3_1 = create_ResNet(2,self.n_filters,self.n_filters,down_sample = False)\n","        self.conv3x3_2 = create_ResNet(2,self.n_filters,self.n_filters*2)\n","        self.conv3x3_3 = create_ResNet(2,self.n_filters*2,self.n_filters*4)\n","        self.conv3x3_4 = create_ResNet(2,self.n_filters*4,self.n_filters*8)\n","        self.avg_pooling = nn.AvgPool2d(7)\n","        self.flat = self.compute_out_shape()\n","        self.avg_pooling = nn.AvgPool2d(self.flat[-1])\n","        self.fc = nn.Linear(self.flat[1],output_dim)\n","        \n","        \n","    def compute_out_shape(self):\n","        # Compute the shape of the output tensor of the convNet\n","        dummy = torch.FloatTensor(np.ones((1,self.n_channels,self.input_size,self.input_size)))\n","        x = self.base_conv(dummy)\n","        x = self.conv3x3_1(x)\n","        x = self.conv3x3_2(x)\n","        x = self.conv3x3_3(x)\n","        x = self.conv3x3_4(x)\n","        return x.shape\n","        \n","    def forward(self, x):\n","        x = self.base_conv(x)\n","        x = self.conv3x3_1(x)\n","        x = self.conv3x3_2(x)\n","        x = self.conv3x3_3(x)\n","        x = self.conv3x3_4(x)\n","        x = self.avg_pooling(x)\n","        x = x.view(-1,self.flat[1])\n","        x = self.fc(x)\n","        return F.softmax(x)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"y9PrwSbI-XyF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593443973241,"user_tz":-120,"elapsed":774,"user":{"displayName":"Samuel Beaussant","photoUrl":"","userId":"05395758280539869398"}}},"source":["# TODO : create clean ResLayer pytorch style that can be printed as ResLayer\n","# try callbacks for early stopping\n","# add lr schedule\n","\n","def create_conv_net( activation,n_input,output_activation,conv_type,num_filters,kernel_n,stride,padding,normalize=False):\n","    \"\"\"Create a convnet:\n","        args :\n","            activation,padding,normalize,stride,kernel_n,num_filters : same as ResidualBlock\n","            output_activation : activation of last layer\n","            conv_type : convolution type \n","    \"\"\"\n","    layers = []\n","    size = len(num_filters)\n","    for j in range(size):\n","        act = activation if j < size-1 else output_activation\n","        if j==0 :\n","            layers += [\n","                conv_type(n_input,num_filters[j],kernel_n[j],stride[j],padding[j])\n","            ]\n","            if normalize :\n","                layers+= [nn.BatchNorm2d(num_filters[j])]\n","            layers+= [act()]\n","        else : \n","            layers += [\n","                conv_type(num_filters[j-1],num_filters[j],kernel_n[j],stride[j],padding[j])\n","            ]\n","            if normalize :\n","                layers+= [nn.BatchNorm2d(num_filters[j])]\n","            #if j < size - 1 :\n","            layers+= [act()]\n","        \n","    return nn.Sequential(*layers)\n","\n","\n","class ResidualBlock(nn.Module):\n","    \"\"\"\n","        Build a residual block for ResNet\n","            args : \n","                n_layer : number of layers\n","                n_channels : number of inputs channels\n","                stride, padding, n_filters, kernel_size : same as conv2d\n","                act : activation fonction\n","                batch_norm (bool) : should add batch_norm\n","                same : use same padding\n","    \"\"\"\n","    def __init__(self,n_layer, n_channels, n_filters,padding = 0, kernel_size=3,stride=1,act=nn.ReLU,down_sample = True,batch_norm= True):\n","        super(ResidualBlock, self).__init__()   \n","        self.padding = [(kernel_size-1)//2] * n_layer\n","        self.stride = [2] + [1] * (n_layer-1) if down_sample else [1] * n_layer\n","        self.n_filters = [n_filters] * n_layer\n","        self.kernel_size = [kernel_size] * kernel_size\n","        self.res_block = create_conv_net(\n","            act,\n","            n_channels,\n","            act,\n","            nn.Conv2d,\n","            self.n_filters,\n","            self.kernel_size,\n","            self.stride,\n","            self.padding,\n","            batch_norm\n","        )\n","        \n","        \n","        \n","    def forward(self,x):\n","        res = x\n","        out = self.res_block(x)\n","        # if dimensions does not match, we perform 1x1 conv\n","        if x.shape[1] != out.shape[1] :\n","          if res.is_cuda:\n","            res = nn.Conv2d(x.shape[1],out.shape[1],1,2,0).to(device)(res)\n","          else :\n","            res = nn.Conv2d(x.shape[1],out.shape[1],1,2,0)(res)\n","        return F.relu(out+res)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"FCo42IUENNGU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593443978688,"user_tz":-120,"elapsed":869,"user":{"displayName":"Samuel Beaussant","photoUrl":"","userId":"05395758280539869398"}}},"source":["def weights_init(m):\n","  # Init weights of the network\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        nn.init.constant_(m.bias.data, 0)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"QTjSfBDm-jhm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593443985076,"user_tz":-120,"elapsed":806,"user":{"displayName":"Samuel Beaussant","photoUrl":"","userId":"05395758280539869398"}},"outputId":"ce5597ab-b41c-4210-d85a-9386e08e63fb"},"source":["if torch.cuda.is_available():\n","    device = torch.device(\"cuda:0\")\n","else:\n","    device = torch.device(\"cpu\")\n","print(device)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gQVcMKq0-bBp","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593448078362,"user_tz":-120,"elapsed":728,"user":{"displayName":"Samuel Beaussant","photoUrl":"","userId":"05395758280539869398"}}},"source":["# Hyper parameters\n","lr = 1e-4\n","BATCH_SIZE = 64\n","EPOCH = 10\n","OUTPUT_DIM = 10\n","\n","# Path for saving the model\n","PATH = \"/content/drive/My Drive/SavedModels/ResNet34_Cifar10.pt\""],"execution_count":90,"outputs":[]},{"cell_type":"code","metadata":{"id":"SheUmuM43h4f","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593448080728,"user_tz":-120,"elapsed":824,"user":{"displayName":"Samuel Beaussant","photoUrl":"","userId":"05395758280539869398"}}},"source":["torch.save(net.state_dict(), PATH)"],"execution_count":91,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUEO2zYD9f0f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593446061980,"user_tz":-120,"elapsed":3355,"user":{"displayName":"Samuel Beaussant","photoUrl":"","userId":"05395758280539869398"}},"outputId":"43d386e8-dd63-40a2-895b-e877f5a25b9a"},"source":["train_loader = torch.utils.data.DataLoader(\n","  torchvision.datasets.CIFAR10(\"/content/drive/My Drive/Data_sets/Cifar/train\", train=True, download=True,\n","                             transform=torchvision.transforms.Compose([\n","                               torchvision.transforms.ToTensor(),\n","                               torchvision.transforms.Normalize(\n","                                 (0.1307,), (0.3081,))\n","                             ])),\n","  batch_size=BATCH_SIZE, shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(\n","  torchvision.datasets.CIFAR10('/content/drive/My Drive/Data_sets/Cifar/test', train=False, download=True,\n","                             transform=torchvision.transforms.Compose([\n","                               torchvision.transforms.ToTensor(),\n","                               torchvision.transforms.Normalize(\n","                                 (0.1307,), (0.3081,))\n","                             ])),\n","  batch_size=1000, shuffle=True)"],"execution_count":69,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d7icysGdAYvX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593450860461,"user_tz":-120,"elapsed":918,"user":{"displayName":"Samuel Beaussant","photoUrl":"","userId":"05395758280539869398"}}},"source":["loss_memory = []\n","net = ResNet34(3,32,OUTPUT_DIM).to(device)\n","opti = optim.Adam(net.parameters(), lr=lr)\n","#loss_function = nn.CrossEntropyLoss()\n","\n","for e in range(EPOCH):\n","    loss_memory = []\n","    correct_epoch = 0\n","    test(net,e)\n","    for batch_idx, (data, targets) in enumerate(train_loader):\n","        correct_batch = 0\n","        out = net(data.to(device))\n","        _, pred = torch.max(out,axis = 1)\n","        labels = torch.zeros((len(targets),OUTPUT_DIM)).to(device)\n","        for i in range(len(targets)):\n","            if pred[i] == targets[i] :\n","                correct_batch += 1\n","                correct_epoch += 1\n","            # one hot encoding\n","            labels[i][targets[i]] = 1\n","        loss = F.mse_loss(out,labels)\n","        loss_memory.append(loss.cpu().detach().numpy())\n","        opti.zero_grad()\n","        loss.backward()\n","        opti.step()\n","        if batch_idx %10 == 0:\n","          print('\\n Batch : {}/{}, Accuracy: ({:.0f}%), loss : {:.4f} '.format(batch_idx,len(train_loader), correct_batch/BATCH_SIZE*100,loss))\n","    avg_loss = np.mean(loss_memory)\n","    print('\\n Training Epoch : {}, Avg.Accuracy: ({:.0f}%), Total loss : {:.4f} '.format(e, correct_epoch/len(train_loader.dataset)*100,avg_loss))\n","\n","torch.save(net.state_dict(), PATH)\n","    "],"execution_count":93,"outputs":[]},{"cell_type":"code","metadata":{"id":"fKyDgg2l0cuD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593446692360,"user_tz":-120,"elapsed":784,"user":{"displayName":"Samuel Beaussant","photoUrl":"","userId":"05395758280539869398"}}},"source":["def test(model,epoch):\n","    correct = 0\n","    loss_memory = []\n","    with torch.no_grad():\n","        for batch_idx, (data, targets) in enumerate(test_loader):\n","            out = net(data.to(device))\n","            _, pred = torch.max(out,axis = 1)\n","            labels = torch.zeros((len(targets),OUTPUT_DIM)).to(device)\n","            for i in range(len(targets)):\n","                if pred[i] == targets[i] :\n","                    correct += 1\n","                labels[i][targets[i]] = 1\n","            loss = F.mse_loss(out,labels)\n","            loss_memory.append(loss.cpu().detach().numpy())\n","        total_loss = np.sum(loss_memory)\n","        print('\\n Test Epoch : {},  Accuracy: ({:.0f}%), Total loss : {:.4f} '.format(epoch, correct/len(test_loader.dataset)*100,total_loss))"],"execution_count":73,"outputs":[]}]}